{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gIoa8bjAHzAT"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNVejjRjIHLQ",
        "outputId": "c8687ec9-0f1f-4b47-97fd-43388dfe14e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHNDSHVnYEgV"
      },
      "outputs": [],
      "source": [
        "def build(path):\n",
        "  newpath = path + \"/data\"\n",
        "\n",
        "\n",
        "  if not os.path.exists(newpath):\n",
        "    print(\"creating new directory...\")\n",
        "\n",
        "    os.makedirs(newpath)\n",
        "\n",
        "    path1 = path + \"/downSyndrome\"\n",
        "    path2 = path + \"/healty\"\n",
        "\n",
        "\n",
        "    files = os.listdir(path1)\n",
        "    for file in files:\n",
        "      shutil.copy2(os.path.join(path1, file), newpath)\n",
        "\n",
        "\n",
        "    files = os.listdir(path2)\n",
        "    for file in files:\n",
        "      shutil.copy2(os.path.join(path2, file), newpath)\n",
        "\n",
        "  else:\n",
        "    print(\"data already exists\")\n",
        "\n",
        "\n",
        "  data = os.listdir(newpath)\n",
        "  random.shuffle(data)\n",
        "  split_1 = int(0.8 * len(data))\n",
        "  split_2 = int(0.9 * len(data))\n",
        "  train = data[:split_1]\n",
        "  valid = data[split_1:split_2]\n",
        "  test = data[split_2:]\n",
        "\n",
        "\n",
        "  return train, valid, test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6DgAdhTYsiT",
        "outputId": "54593554-09a4-466e-ea8a-d39e1c289555"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "creating new directory...\n"
          ]
        }
      ],
      "source": [
        "path = \"/content/drive/MyDrive/archive\"\n",
        "data = build(path)\n",
        "\n",
        "\n",
        "train_labels = []\n",
        "val_labels = []\n",
        "test_labels = []\n",
        "\n",
        "\n",
        "train, val, test = data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFurC3p7ZIGc"
      },
      "outputs": [],
      "source": [
        "for path in train:\n",
        "    if \"down\" in path:\n",
        "      train_labels.append(1)\n",
        "    else:\n",
        "      train_labels.append(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJXT5wKfZ6F3"
      },
      "outputs": [],
      "source": [
        "for path in test:\n",
        "  if \"down\" in path:\n",
        "    test_labels.append(1)\n",
        "  else:\n",
        "    test_labels.append(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFbKhQyiaaHU"
      },
      "outputs": [],
      "source": [
        "for path in val:\n",
        "  if \"down\" in path:\n",
        "    val_labels.append(1)\n",
        "  else:\n",
        "    val_labels.append(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eadlVeAWa1fv"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "base_path = '/content/drive/MyDrive/archive/processed_data/'\n",
        "\n",
        "if not os.path.exists(base_path):\n",
        "  os.makedirs(base_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6egwjS_bK8p"
      },
      "outputs": [],
      "source": [
        "def save_processed_imgs(images, path, labels):\n",
        "  data_path = base_path + path\n",
        "  if not os.path.exists(data_path):\n",
        "    os.makedirs(data_path)\n",
        "\n",
        "  downSyndrome_path = os.path.join(data_path, \"downSyndrome\")\n",
        "  healthy_path = os.path.join(data_path, \"healthy\")\n",
        "\n",
        "  if not os.path.exists(downSyndrome_path):\n",
        "    os.makedirs(downSyndrome_path)\n",
        "  if not os.path.exists(healthy_path):\n",
        "    os.makedirs(healthy_path)\n",
        "\n",
        "  for index, image in enumerate(images):\n",
        "    if image is None or image.size == 0:\n",
        "      print(f\"Skipping image {index} due to zero size.\")\n",
        "      continue\n",
        "\n",
        "    if index >= len(labels):\n",
        "      print(f\"Skipping image {index} because label does not exist.\")\n",
        "      continue\n",
        "\n",
        "    normalized_image = (image - image.min()) / (image.max() - image.min()) * 255\n",
        "    im = Image.fromarray(normalized_image.astype('uint8'))\n",
        "\n",
        "\n",
        "    if labels[index] == 0:\n",
        "      im.save(os.path.join(healthy_path, f'{index}.png'))\n",
        "    else:\n",
        "      im.save(os.path.join(downSyndrome_path, f'{index}.png'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HiuEXwfTcy_C"
      },
      "outputs": [],
      "source": [
        "# For SSD\n",
        "def ssd(dir, image):\n",
        "  image = cv2.imread(dir + image)\n",
        "  detector = cv2.dnn.readNetFromCaffe(\"/content/deploy.prototxt.txt\",\"/content/res10_300x300_ssd_iter_140000.caffemodel\")\n",
        "  img_blob = cv2.dnn.blobFromImage(image)\n",
        "\n",
        "  detector.setInput(img_blob)\n",
        "  detections = detector.forward()\n",
        "  detections = detections[0][0]\n",
        "\n",
        "\n",
        "  df = pd.DataFrame(detections, columns=[\"img_id\", \"is_face\", \"confidence\", \"left\", \"top\", \"right\", \"bottom\"])\n",
        "  df = df[df[\"is_face\"]==1]\n",
        "  df = df[df[\"confidence\"] > 0.9]\n",
        "\n",
        "\n",
        "  for index, instance in df.iterrows():\n",
        "    left = int(instance['left'] * 300)\n",
        "    right = int(instance['right'] * 300)\n",
        "    top = int(instance['top'] * 300)\n",
        "    bottom = int(instance['bottom'] * 300)\n",
        "\n",
        "\n",
        "    if bottom <= 300 and right <= 300:\n",
        "      image = image[top:bottom, left:right]\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRhgbBDzdztU",
        "outputId": "675185a2-8d98-4836-8cfd-ed47b0545af6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping image 52 due to zero size.\n",
            "Skipping image 123 due to zero size.\n",
            "Skipping image 237 due to zero size.\n",
            "Skipping image 368 due to zero size.\n",
            "Skipping image 560 due to zero size.\n",
            "Skipping image 604 due to zero size.\n",
            "Skipping image 622 due to zero size.\n",
            "Skipping image 657 due to zero size.\n",
            "Skipping image 696 due to zero size.\n",
            "Skipping image 704 due to zero size.\n",
            "Skipping image 898 due to zero size.\n",
            "Skipping image 955 due to zero size.\n",
            "Skipping image 1100 due to zero size.\n",
            "Skipping image 1109 due to zero size.\n",
            "Skipping image 1157 due to zero size.\n",
            "Skipping image 1206 due to zero size.\n",
            "Skipping image 1375 due to zero size.\n",
            "Skipping image 1548 due to zero size.\n",
            "Skipping image 1566 due to zero size.\n",
            "Skipping image 1667 due to zero size.\n",
            "Skipping image 1684 due to zero size.\n",
            "Skipping image 1750 due to zero size.\n",
            "Skipping image 1916 due to zero size.\n",
            "Skipping image 1927 due to zero size.\n",
            "Skipping image 2054 due to zero size.\n",
            "Skipping image 2093 due to zero size.\n",
            "Skipping image 2115 due to zero size.\n",
            "Skipping image 2132 due to zero size.\n",
            "Skipping image 2156 due to zero size.\n",
            "Skipping image 2169 due to zero size.\n",
            "Skipping image 2174 due to zero size.\n",
            "Skipping image 2184 due to zero size.\n",
            "Skipping image 2248 due to zero size.\n",
            "Skipping image 2272 due to zero size.\n",
            "Skipping image 54 due to zero size.\n",
            "Skipping image 136 due to zero size.\n",
            "Skipping image 168 due to zero size.\n",
            "Skipping image 182 due to zero size.\n",
            "Skipping image 191 due to zero size.\n",
            "Skipping image 225 due to zero size.\n",
            "Skipping image 231 due to zero size.\n",
            "Skipping image 17 due to zero size.\n",
            "Skipping image 71 due to zero size.\n",
            "Skipping image 126 due to zero size.\n",
            "Skipping image 193 due to zero size.\n",
            "Skipping image 197 due to zero size.\n"
          ]
        }
      ],
      "source": [
        "ssd_train = []\n",
        "ssd_val = []\n",
        "ssd_test = []\n",
        "dir = \"/content/drive/MyDrive/archive/data/\"\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/archive/processed_data/'\n",
        "\n",
        "if not os.path.exists(data_dir):\n",
        "  for image in train:\n",
        "    if image is not None:\n",
        "      ssd_train.append(ssd(dir, image))\n",
        "  save_processed_imgs(ssd_train, 'train', train_labels)\n",
        "\n",
        "  for image in val:\n",
        "    if image is not None:\n",
        "      ssd_val.append(ssd(dir, image))\n",
        "  save_processed_imgs(ssd_val, 'val', val_labels)\n",
        "\n",
        "  for image in test:\n",
        "    if image is not None:\n",
        "      ssd_test.append(ssd(dir, image))\n",
        "  save_processed_imgs(ssd_test, 'test', test_labels)\n",
        "\n",
        "else:\n",
        "  print(\"processed images already present.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "lxxowkn0d-Tf",
        "outputId": "9dbf7c57-35b8-4c88-b832-939b4cff290f"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Error while calling cudaGetDevice(&the_device_id) in file /tmp/pip-install-nj6k7_al/dlib_dd113b177fa647df963e4f896c088a8b/dlib/cuda/gpu_data.cpp:204. code: 35, reason: CUDA driver version is insufficient for CUDA runtime version",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-920a94a4be48>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmtcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmtcnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMTCNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mface_recognition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/face_recognition/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'1.2.3'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_image_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_locations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_face_locations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_landmarks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_encodings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompare_faces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_distance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/face_recognition/api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mcnn_face_detection_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_recognition_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn_face_detector_model_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mcnn_face_detector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn_face_detection_model_v1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn_face_detection_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mface_recognition_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_recognition_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mface_recognition_model_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error while calling cudaGetDevice(&the_device_id) in file /tmp/pip-install-nj6k7_al/dlib_dd113b177fa647df963e4f896c088a8b/dlib/cuda/gpu_data.cpp:204. code: 35, reason: CUDA driver version is insufficient for CUDA runtime version"
          ]
        }
      ],
      "source": [
        "# For MTCNN\n",
        "import dlib\n",
        "from imutils import paths\n",
        "from mtcnn.mtcnn import MTCNN\n",
        "import face_recognition\n",
        "\n",
        "\n",
        "def mtcnn(dir, image):\n",
        "  image = face_recognition.load_image_file(dir + image)\n",
        "\n",
        "  detector = MTCNN()\n",
        "  face_locations = detector.detect_faces(image)\n",
        "\n",
        "  for face in zip(face_locations):\n",
        "    x,y,w,h = face[0]['box']\n",
        "    landmarks = face[0]\n",
        "\n",
        "  image = image[y:y+h, x:x+w]\n",
        "  return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "by09QM9Ib5Rn",
        "outputId": "22f1485c-b89f-4dbe-bc43-1347f68e3d45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processed images already present.\n"
          ]
        }
      ],
      "source": [
        "mtcnn_train = []\n",
        "mtcnn_val = []\n",
        "mtcnn_test = []\n",
        "dir = \"/content/drive/MyDrive/archive/data/\"\n",
        "\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/archive/processed_data/'\n",
        "\n",
        "\n",
        "if not os.path.exists(data_dir):\n",
        "  for image in train:\n",
        "    if image is not None:\n",
        "      mtcnn_train.append(mtcnn(dir, image))\n",
        "  save_processed_imgs(mtcnn_train, 'train', train_labels)\n",
        "\n",
        "  for image in val:\n",
        "    if image is not None:\n",
        "      mtcnn_val.append(mtcnn(dir, image))\n",
        "  save_processed_imgs(mtcnn_val, 'val', val_labels)\n",
        "\n",
        "  for image in test:\n",
        "    if image is not None:\n",
        "      mtcnn_test.append(mtcnn(dir, image))\n",
        "  save_processed_imgs(mtcnn_test, 'test', test_labels)\n",
        "\n",
        "else:\n",
        "  print(\"processed images already present.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "viRtXEkxeMVo"
      },
      "outputs": [],
      "source": [
        "#Classification Model\n",
        "from keras.preprocessing.image import img_to_array\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpggcjn0fA5-"
      },
      "outputs": [],
      "source": [
        "def normalise(image):\n",
        "  image = cv2.resize(image, (224, 224))\n",
        "\n",
        "  if len(image.shape) == 2: # If image is grayscale, convert to RGB\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "  image = img_to_array(image)\n",
        "  image = image / 255.0\n",
        "  return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCpgrwOye1J7",
        "outputId": "1b8b0dc7-f8a5-4c0c-c9fc-6b26724a4334"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2365 images belonging to 2 classes.\n",
            "Found 293 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen=ImageDataGenerator(preprocessing_function = normalise)\n",
        "validation_datagen = ImageDataGenerator(preprocessing_function = normalise)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "directory=\"/content/drive/MyDrive/archive/processed_data/train\",\n",
        "target_size=(224, 224),\n",
        "batch_size=8,\n",
        "class_mode=\"binary\"\n",
        ")\n",
        "\n",
        "val_generator = validation_datagen.flow_from_directory(\n",
        "directory=\"/content/drive/MyDrive/archive/processed_data/val\",\n",
        "target_size=(224, 224),\n",
        "batch_size=8,\n",
        "class_mode=\"binary\"\n",
        ")\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "monitor=\"val_accuracy\",\n",
        "min_delta=0.05,\n",
        "patience=15,\n",
        "verbose=1,\n",
        "mode=\"max\",\n",
        "baseline=None,\n",
        "restore_best_weights=True\n",
        ")\n",
        "\n",
        "METRICS = [\n",
        "tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "tf.keras.metrics.Precision(name='precision'),\n",
        "tf.keras.metrics.Recall(name='recall')\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5DEFMrWfKih",
        "outputId": "6e449445-7c0a-4c17-9221-037e4273fbb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Using ResNet50\n",
        "import os\n",
        "\n",
        "path_checkpoint = \"model_cp_resnet.ckpt\"\n",
        "directory_checkpoint = os.path.dirname(path_checkpoint)\n",
        "\n",
        "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=path_checkpoint,\n",
        "save_weights_only=True,\n",
        "verbose=1)\n",
        "\n",
        "# Define input layer\n",
        "input_layer = tf.keras.layers.Input(shape=(224, 224, 3), name='image_input')\n",
        "\n",
        "# Create ResNet50 Model\n",
        "resnet = tf.keras.applications.ResNet50(\n",
        "include_top=False,\n",
        "weights='imagenet',\n",
        "input_tensor=input_layer,\n",
        "pooling=None\n",
        ")\n",
        "\n",
        "# Freeze ResNet50 layers\n",
        "for layer in resnet.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "# Add custom classification layers\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(resnet.output)\n",
        "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "x = tf.keras.layers.Dense(8, activation='relu')(x)\n",
        "predictions = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# Create final model\n",
        "model = tf.keras.models.Model(inputs=input_layer, outputs=predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4H5xLsQcdCj",
        "outputId": "b897588b-753f-4c98-f544-c087a0eb346f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-20-273ea5570688>:5: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "296/296 [==============================] - 461s 2s/step - loss: 0.6937 - accuracy: 0.5031 - precision: 0.5034 - recall: 0.9971 - val_loss: 0.6935 - val_accuracy: 0.4608 - val_precision: 0.4608 - val_recall: 1.0000\n",
            "Epoch 2/100\n",
            "296/296 [==============================] - 464s 2s/step - loss: 0.6932 - accuracy: 0.5040 - precision: 0.5040 - recall: 0.9992 - val_loss: 0.6935 - val_accuracy: 0.4608 - val_precision: 0.4608 - val_recall: 1.0000\n",
            "Epoch 3/100\n",
            "296/296 [==============================] - 464s 2s/step - loss: 0.6932 - accuracy: 0.5044 - precision: 0.5042 - recall: 0.9992 - val_loss: 0.6935 - val_accuracy: 0.4608 - val_precision: 0.4608 - val_recall: 1.0000\n",
            "Epoch 4/100\n",
            "296/296 [==============================] - 461s 2s/step - loss: 0.6931 - accuracy: 0.5061 - precision: 0.5051 - recall: 0.9924 - val_loss: 0.6936 - val_accuracy: 0.4608 - val_precision: 0.4608 - val_recall: 1.0000\n",
            "Epoch 5/100\n",
            "296/296 [==============================] - 426s 1s/step - loss: 0.6932 - accuracy: 0.5040 - precision: 0.5040 - recall: 0.9983 - val_loss: 0.6936 - val_accuracy: 0.4608 - val_precision: 0.4608 - val_recall: 1.0000\n",
            "Epoch 6/100\n",
            "296/296 [==============================] - 461s 2s/step - loss: 0.6930 - accuracy: 0.5053 - precision: 0.5047 - recall: 0.9992 - val_loss: 0.6936 - val_accuracy: 0.4608 - val_precision: 0.4608 - val_recall: 1.0000\n",
            "Epoch 7/100\n",
            "296/296 [==============================] - 461s 2s/step - loss: 0.6931 - accuracy: 0.5053 - precision: 0.5047 - recall: 0.9975 - val_loss: 0.6936 - val_accuracy: 0.4608 - val_precision: 0.4608 - val_recall: 1.0000\n",
            "Epoch 8/100\n",
            "296/296 [==============================] - 461s 2s/step - loss: 0.6932 - accuracy: 0.5032 - precision: 0.5036 - recall: 0.9958 - val_loss: 0.6936 - val_accuracy: 0.4608 - val_precision: 0.4608 - val_recall: 1.0000\n",
            "Epoch 9/100\n",
            "296/296 [==============================] - 461s 2s/step - loss: 0.6931 - accuracy: 0.5057 - precision: 0.5049 - recall: 0.9983 - val_loss: 0.6936 - val_accuracy: 0.4608 - val_precision: 0.4608 - val_recall: 1.0000\n",
            "Epoch 10/100\n",
            "296/296 [==============================] - 462s 2s/step - loss: 0.6934 - accuracy: 0.5057 - precision: 0.5051 - recall: 0.9555 - val_loss: 0.6936 - val_accuracy: 0.4608 - val_precision: 0.4608 - val_recall: 1.0000\n",
            "Epoch 11/100\n",
            "296/296 [==============================] - 460s 2s/step - loss: 0.6937 - accuracy: 0.5133 - precision: 0.5101 - recall: 0.8683 - val_loss: 0.6937 - val_accuracy: 0.4608 - val_precision: 0.4608 - val_recall: 1.0000\n",
            "Epoch 12/100\n",
            "296/296 [==============================] - 457s 2s/step - loss: 0.6940 - accuracy: 0.5006 - precision: 0.5024 - recall: 0.9555 - val_loss: 0.6937 - val_accuracy: 0.4608 - val_precision: 0.4608 - val_recall: 1.0000\n",
            "Epoch 13/100\n",
            "296/296 [==============================] - 457s 2s/step - loss: 0.6931 - accuracy: 0.5023 - precision: 0.5032 - recall: 0.9950 - val_loss: 0.6937 - val_accuracy: 0.4608 - val_precision: 0.4608 - val_recall: 1.0000\n",
            "Epoch 14/100\n",
            "296/296 [==============================] - 459s 2s/step - loss: 0.6928 - accuracy: 0.5061 - precision: 0.5052 - recall: 0.9765 - val_loss: 0.6937 - val_accuracy: 0.4608 - val_precision: 0.4608 - val_recall: 1.0000\n",
            "Epoch 15/100\n",
            "296/296 [==============================] - 422s 1s/step - loss: 0.6934 - accuracy: 0.5015 - precision: 0.5028 - recall: 0.9849 - val_loss: 0.6937 - val_accuracy: 0.4608 - val_precision: 0.4608 - val_recall: 1.0000\n",
            "Epoch 16/100\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.5125 - precision: 0.5085 - recall: 0.9807Restoring model weights from the end of the best epoch: 1.\n",
            "296/296 [==============================] - 416s 1s/step - loss: 0.6931 - accuracy: 0.5125 - precision: 0.5085 - recall: 0.9807 - val_loss: 0.6937 - val_accuracy: 0.4608 - val_precision: 0.4608 - val_recall: 1.0000\n",
            "Epoch 16: early stopping\n"
          ]
        }
      ],
      "source": [
        "from keras.optimizers import RMSprop\n",
        "\n",
        "model.compile(optimizer=RMSprop(learning_rate=0.0001), loss='binary_crossentropy', metrics=METRICS)\n",
        "\n",
        "history = model.fit_generator(\n",
        "train_generator,\n",
        "steps_per_epoch=len(train_generator),\n",
        "epochs=100,\n",
        "validation_data=val_generator,\n",
        "validation_steps=len(val_generator),\n",
        "callbacks=[early_stopping]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-RsPA1kcnaF"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='train')\n",
        "plt.plot(history.history['val_accuracy'], label='val')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBOyTbymc5wx"
      },
      "outputs": [],
      "source": [
        "# Using custom CNN Model\n",
        "\n",
        "import os\n",
        "\n",
        "path_checkpoint = \"model_cp_custom.ckpt\"\n",
        "directory_checkpoint = os.path.dirname(path_checkpoint)\n",
        "\n",
        "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=path_checkpoint,\n",
        "save_weights_only=True,\n",
        "verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjtNu6vjc8oB"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(224, 224, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Flatten()) # this converts our 3D feature maps to 1D feature vectors\n",
        "model.add (Dense (64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "optimizer='rmsprop' ,\n",
        "metrics=METRICS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6c0ZgCfdGSV"
      },
      "outputs": [],
      "source": [
        "history = model.fit_generator(\n",
        "train_generator,\n",
        "steps_per_epoch=250,\n",
        "epochs=100,\n",
        "validation_data=val_generator,\n",
        "validation_steps=20,\n",
        "callbacks=[early_stopping]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcFWGdWNdMIW"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='train')\n",
        "plt.plot(history.history['val_accuracy'], label='val')\n",
        "plt.legend()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}